apiVersion: v1
kind: ConfigMap
metadata:
  name: logstash
data:
  httpx.conf: |
    input {
      file {
        path => "/tmp/httpx-result.txt"
        codec => "json"
        start_position => "beginning"
        sincedb_path => "/dev/null"
        exit_after_read => true
        mode => "read"
        file_chunk_size => 3145728  # 3MB
      }
    }
    filter {
      mutate {
        convert => ["port","integer"]
        convert => ["words","integer"]
        convert => ["lines","integer"]
        convert => ["status-code","integer"]
        convert => ["content-length","integer"]
      }
      mutate {
        split => { "input" => ":" }
        add_field => { "domain" => "%{[input][0]}" }
      }
      mutate {
        # it is needed and can not be in last mutate block.
        # Each mutation must be in its own code block if the sequence of operations needs to be preserved.
        join => { "input" => ":" }
      }
    }
    output {
      elasticsearch {
        hosts => ["elasticsearch-master:9200"]
        index => "web-service"
        document_id => "%{url}"

        scripted_upsert => true
        action => "update"
        script_lang => "painless"
        script_type => "inline"
        script => "
          if(ctx.op == 'create') {
            ctx._source=params.event;
            ctx._source.first_create_time = params.event.get('timestamp');
          } else {
            String old = ctx._source.get('first_create_time');

            for (entry in params.event.entrySet()) {
              ctx._source[entry.getKey()] = entry.getValue()
            }
            //ctx._source = params.event;

            ctx._source.last_update_time = params.event.get('timestamp');
            ctx._source.first_create_time = old;
          }
        "
      }
    }

  probe_favicon.conf: |
    input {
      file {
        path => "/tmp/httpx-result.txt"
        codec => "json"
        start_position => "beginning"
        sincedb_path => "/dev/null"
        exit_after_read => true
        mode => "read"
        file_chunk_size => 3145728  # 3MB
      }
    }

    filter {
      mutate {
        convert => ["port","integer"]
        convert => ["words","integer"]
        convert => ["lines","integer"]
        convert => ["status-code","integer"]
        convert => ["content-length","integer"]
      }
      mutate {
        split => { "input" => ":" }
        add_field => { "domain" => "%{[input][0]}" }
      }
      mutate {
        # it is needed and can not be in last mutate block.
        # Each mutation must be in its own code block if the sequence of operations needs to be preserved.
        join => { "input" => ":" }
      }
    }
    output {
      if ("image" in [content_type]) {
        elasticsearch {
          hosts => ["elasticsearch-master:9200"]
          index => "favicon"
          document_id => "%{url}"

          scripted_upsert => true
          action => "update"
          script_lang => "painless"
          script_type => "inline"
          script => "
            if(ctx.op == 'create') {
              ctx._source=params.event;
              ctx._source.first_create_time = params.event.get('timestamp');
            } else {
              String old = ctx._source.get('first_create_time');

              for (entry in params.event.entrySet()) {
                ctx._source[entry.getKey()] = entry.getValue()
              }
              //ctx._source = params.event;

              ctx._source.last_update_time = params.event.get('timestamp');
              ctx._source.first_create_time = old;
            }
          "
        }
      }
    }

  probe_tls.conf: |
    input {
      file {
        path => "/tmp/tls-result.txt"
        codec => "json"
        start_position => "beginning"
        sincedb_path => "/dev/null"
        exit_after_read => true
        mode => "read"
        file_chunk_size => 3145728  # 3MB
      }
    }

    filter {
      mutate {
        convert => ["port","integer"]
      }
    }
    output {
      elasticsearch {
        hosts => ["elasticsearch-master:9200"]
        index => "tls"
        document_id => "%{host}_%{ip}_%{port}"

        scripted_upsert => true
        action => "update"
        script_lang => "painless"
        script_type => "inline"
        script => "
          if(ctx.op == 'create') {
            ctx._source=params.event;
            ctx._source.first_create_time = params.event.get('timestamp');
          } else {
            String old = ctx._source.get('first_create_time');

            for (entry in params.event.entrySet()) {
              ctx._source[entry.getKey()] = entry.getValue()
            }
            //ctx._source = params.event;

            ctx._source.last_update_time = params.event.get('timestamp');
            ctx._source.first_create_time = old;
          }
        "
      }
    }
  probe_port.conf: |
    input {
      file {
        path => "/tmp/port-result.txt"
        codec => json {
          target => "tmp_field"
        }
        start_position => "beginning"
        sincedb_path => "/dev/null"
        exit_after_read => true
        mode => "read"
        file_chunk_size => 3145728  # 3MB
      }
    }

    filter {
      mutate {
        convert => ["tmp_field.port","integer"]
      }

      if !("" in [tmp_field][host]) {
        mutate {
          add_field => { "[tmp_field][host]" => "no-host" }
          add_field => { "[tmp_field][link]" => "[tmp_field][ip]:[tmp_field][port]" }
        }
      } else {
        mutate {
          add_field => { "[tmp_field][link]" => "[tmp_field][host]:[tmp_field][port]" }
        }
      }
    }
    output {
      elasticsearch {
        hosts => ["elasticsearch-master:9200"]
        index => "port"
        document_id => "%{[tmp_field][ip]}_%{[tmp_field][host]}_%{[tmp_field][port]}"
        scripted_upsert => true
        action => "update"
        script_lang => "painless"
        script_type => "inline"
        script => "
          if(ctx.op == 'create') {
            ctx._source=params.event.tmp_field;
            ctx._source.first_create_time = params.event.tmp_field.get('timestamp');
          } else {
            String old = ctx._source.get('first_create_time');

            for (entry in params.event.entrySet()) {
              ctx._source[entry.getKey()] = entry.getValue()
            }
            //ctx._source = params.event;

            ctx._source.last_update_time = params.event.tmp_field.get('timestamp');
            ctx._source.first_create_time = old;
          }
        "
      }

      if ([tmp_field][host]!="no-host") {
        file {
          path => "/tmp/url.txt"
          codec => line {
            format => "%{[tmp_field][host]}:%{[tmp_field][port]}"
          }
        }
      } else {
        file {
          path => "/tmp/url.txt"
          codec => line {
            format => "%{[tmp_field][ip]}:%{[tmp_field][port]}"
          }
        }
      }
    }

  subfinder.conf: |
    input {
      file {
        path => "/tmp/subdomain-result.txt"
        codec => "json"
        start_position => "beginning"
        sincedb_path => "/dev/null"
        exit_after_read => true
        mode => "read"
        file_chunk_size => 3145728  # 3MB
      }
    }

    filter {
      mutate {
        convert => ["port","integer"]
      }
    }
    output {
      elasticsearch {
        hosts => ["elasticsearch-master:9200"]
        index => "subdomain"
        document_id => "%{host}"

        scripted_upsert => true
        action => "update"
        script_lang => "painless"
        script_type => "inline"
        script => "
          if(ctx.op == 'create') {
            ctx._source=params.event;
            ctx._source.first_create_time = params.event.get('@timestamp');
          } else {
            String old = ctx._source.get('first_create_time');

            for (entry in params.event.entrySet()) {
              ctx._source[entry.getKey()] = entry.getValue()
            }
            //ctx._source = params.event;

            ctx._source.last_update_time = params.event.get('@timestamp');
            ctx._source.first_create_time = old;
          }
        "
      }

      if [host] {
        file {
          path => "/tmp/subdomain.txt"
          codec => line {
            format => "%{host}"
          }
        }
      }
    }
