apiVersion: v1
kind: ConfigMap
metadata:
  name: logstash-config-sld
data:
  sld.conf: |
    input {
      # Read all documents from Elasticsearch matching the given query
      elasticsearch {
        hosts => "elasticsearch-master:9200"
        index => "subdomain"
        query => '{
          "_source": "parsed-domain.registered_domain",
          "query": {
            "query_string": {
              "query": "org:${ORG}"
            }
          }
        }'
      }
    }

    output {
      file {
          path => "/tmp/host.txt"
          codec => line {
            format => "%{[parsed-domain][registered_domain]}"
          }
      }
    }

  save.conf: |
    input {
      file {
        path => "/tmp/sld.txt"
        start_position => "beginning"
        sincedb_path => "/dev/null"
        exit_after_read => true
        mode => "read"
      }
    }

    filter {
      csv {
        columns =>  ["sld"]
      }

      mutate {
        add_field => { "source" => "${SOURCE}" }
        add_field => { "org" => ["${ORG}"] }
        add_field => { "host" => "%{sld}" }
        remove_field => ["host", "path", "message"]
      }
    }

    output {
      elasticsearch {
        hosts => "{{.Values.kibana.elasticsearchHosts}}"
        index => "sld"
        document_id => "%{sld}"

        scripted_upsert => true
        action => "update"
        script_lang => "painless"
        script_type => "inline"
        script => "
          if(ctx.op == 'create') {
            ctx._source=params.event;
            ctx._source.first_create_time = params.event.get('timestamp');
          } else {
            String old = ctx._source.get('first_create_time');

            for (entry in params.event.entrySet()) {
              ctx._source[entry.getKey()] = entry.getValue()
            }
            //ctx._source = params.event;

            ctx._source.last_update_time = params.event.get('timestamp');
            ctx._source.first_create_time = old;
          }
        "
      }
    }

  save-enscan.conf: |
    input {
      file {
        path => "/tmp/outs/*.json"
        start_position => "beginning"
        sincedb_path => "/dev/null"
        exit_after_read => true
        mode => "read"
        codec => "json"
        file_chunk_size => 3145728  # 3MB
      }
    }

    filter {
      split {
        field =>  ["icp"]
      }
      mutate {
        add_field => {
          "sld" => "%{[icp][domain]}"
        }
        remove_field => ["icp.company_name", "host"]
      }
    }

    output {
      file {
        path => "/tmp/sld/%{[enterprise_info][0][name]}.txt"
        codec => line {
          format => "%{[icp][domain]}"
        }
      }
      elasticsearch {
        hosts => "{{.Values.kibana.elasticsearchHosts}}"
        index => "sld"
        document_id => "%{sld}"

        scripted_upsert => true
        action => "update"
        script_lang => "painless"
        script_type => "inline"
        script => "
          if(ctx.op == 'create') {
            ctx._source=params.event;
            ctx._source.first_create_time = params.event.get('timestamp');
          } else {
            String old = ctx._source.get('first_create_time');

            for (entry in params.event.entrySet()) {
              ctx._source[entry.getKey()] = entry.getValue()
            }
            //ctx._source = params.event;

            ctx._source.last_update_time = params.event.get('timestamp');
            ctx._source.first_create_time = old;
          }
        "
      }
    }